---
title: "Final Project"
author: "Matthew Maroney"
date: "`r Sys.Date()`"
format: html
---

In this project, I will examine political polarization. Polarization has been an incredibly impactful trend in recent American politics. Both the left and right in this country are becoming more extreme over time. Congress has failed to produce bipartisan cooperation for at least the past two decades. Each party uses the filibuster to hold the other hostage when they are in power. This leaves America falling behind the rest of the world as we are not able to respond effectively to problems the country faces.

In this project I will analyze a set of tweets from politicians across the country. I will analyze the sentiment of words in their tweet based on whether the tweet is partisan or nonpartisan. From that, I hope to glean information about the kind of words politicians are using to describe partisan vs. nonpartisan issues. I will also analyze tweets based on the intended audience, national or local, and intended message focus, such as policy, personal, or voter mobilization. If my intuitions are correct, partisan tweets and tweets aimed at the national constituency will use more negative language than nonpartisan tweets and those aimed at a local constituency. This will backup arguments that political polarization is happening in this country and that bipartisan cooperation is extremely difficult.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading Necessary Packages

```{r  message=FALSE}
rm(list=ls())
library(tidyverse)
library(tidytext)
library(lubridate)
library(ggthemes)
library(SnowballC)
```

Reading in data and eliminating unnecessary variables

```{r}
data2 = read_csv("political_social_media.csv") %>%
  select(-"_golden", -"_unit_state", -"_trusted_judgments", -"_last_judgment_at", -"audience:confidence", -message, -"message:confidence", -"orig__golden", -"audience_gold", -"bias_gold", -bioid, -embed, -id, -label, -"message_gold", -source, -"bias:confidence", -"_unit_id")
```

```{r}
data3 = read_csv("political_social_media.csv") %>%
  select(-"_golden", -"_unit_state", -"_trusted_judgments", -"_last_judgment_at", -"audience:confidence", -"message:confidence", -"orig__golden", -"audience_gold", -"bias_gold", -bioid, -embed, -id, -label, -"message_gold", -source, -"bias:confidence", -"_unit_id", -bias, -audience)
```

```{r}
data.token = data2 %>%
  unnest_tokens(word, text, token = "words") %>% 
  select(-audience)
```

Here, I've "tokenized" my data. This means I've extracted each individual word from all the tweets and categorized them by partisan/nonpartisan based on the original tweet the word came from.

```{r}
data.token %>%
  count(word, sort = TRUE) %>%
  head(n = 10)
```

Here, I've found the most common words across tweets. I will go on to remove "stop words," which are words which are not useful for my analysis, such as overly common words like "the," "to," "and," or "of," alongside things which are not words which tokenization still gathered up, such as "t.co" or "http."

```{r}
data("stop_words")
data.token_nostop = data.token %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("http","t.co","amp","day","rt","1","week","watch","morning","2","3","4","5","6","7","8","9","10","2013","2014","2015","2016","2017","2018","2019"))
```

Here, I've removed "stop words." These are common words (or other things which commonly appear in tweets from politicians, like numbers and years) which aren't relevant for sentiment analysis. I've removed them from my data set here and will use this code many times again throughout this project to remove the same set of stop words from the data.

```{r}
data.token_nostop %>%
  count(word, sort = TRUE) %>%
  head(n = 100)
```

This is the new list of the most frequent words after stop words have been removed.

```{r}
sent_words = get_sentiments("afinn")
```

```{r}
tweet.sentiments = data.token_nostop %>%
  inner_join(sent_words, by = "word") %>%
  ungroup() %>%
  distinct()
```

Here, I've brought in "sent_words," this is a large set of words each with a sentiment score assigned to it based on its positivity or negativity.

Next, I've assigned each word a sentiment score based on what's in the "sent_words" data set.

Partisan Tweet Sentiments - Bias Variable

```{r}
partisan.sentiments = tweet.sentiments %>%
  filter(bias=="partisan")
```

```{r}
mean(partisan.sentiments$value)
```

```{r}
partisan.value = partisan.sentiments$value 
hist(partisan.value)
```

The mean sentiment value for any given word in tweets marked as "partisan" is -0.24. As you can see from the histogram of sentiment values of words in partisan tweets, there are many more negative words than positive words. This indicates politicians use more charged and negative language when discussing partisan issues.

Neutral Tweet Sentiments - Bias Variable

```{r}
neutral.sentiments = tweet.sentiments %>%
  filter(bias=="neutral")
```

```{r}
mean(neutral.sentiments$value)
```

```{r}
neutral.value = neutral.sentiments$value
hist(neutral.value)
```

The mean sentiment for any given word in tweets marked as "neutral" is 0.02, and looking at the histogram there is not that much of a difference in the frequency of positive and negative words. While negative words have a higher peak between -2 and -3, words of low positive sentiment are present more often than words of low negative sentiment, balancing the distribution out.

Overall, we can see that words in partisan tweets are typically more negative. This reflects and backs up the trend of political polarization and the collapse of bipartisanship discussed in the exposition.

Tokenization and Sentiment Gathering - Audience Variable

```{r}
data.token2 = data2 %>%
  unnest_tokens(word, text, token = "words") %>% 
  select(-bias)
```

```{r}
data("stop_words")
data.token_nostop2 = data.token2 %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("http","t.co","amp","day","rt","1","week","watch","morning","2","3","4","5","6","7","8","9","10","2013","2014","2015","2016","2017","2018","2019"))
```

```{r}
tweet.sentiments2 = data.token_nostop2 %>%
  inner_join(sent_words, by = "word") %>%
  ungroup() %>%
  distinct()
```

Sentiment of Tweets aimed at the Nation - Audience Variable

```{r}
national.sentiments = tweet.sentiments2 %>%
  filter(audience=="national")
```

```{r}
mean(national.sentiments$value)
```

```{r}
national.value=national.sentiments$value
hist(national.value)
```

Mean sentiment for words in tweets aimed at the national constituency is -0.13. This is backed up by the histogram which shows words with negative sentiment are much more common in these tweets.

Sentiment of Tweets aimed at a politician's local constituency - Audience Variable

```{r}
cons.sentiments = tweet.sentiments2 %>%
  filter(audience=="constituency")
```

```{r}
mean(cons.sentiments$value)
```

```{r}
cons.value=cons.sentiments$value
hist(cons.value)
```

Mean sentiment value of words in tweets aimed at a politician's local constituency is 0.36. This is reflected in the histogram which shows an intense concentration of positive words in these tweets. This makes sense, as politicians would not discuss their own constituency or local area in a negative manner as they rely on those people for re-election

The difference in mean sentiment of words in tweets aimed at the nation versus a politician's local constituency also backs up the trends discussed up top. While politicians put on a happy face for their voters, they discuss national politics negatively.

Tokenization and Sentiment Gathering - Message Variable

```{r}
data.token3 = data3 %>%
  unnest_tokens(word, text, token = "words")
```

```{r}
data("stop_words")
data.token_nostop3 = data.token3 %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("http","t.co","amp","day","rt","1","week","watch","morning","2","3","4","5","6","7","8","9","10","2013","2014","2015","2016","2017","2018","2019"))
```

```{r}
tweet.sentiments3 = data.token_nostop3 %>%
  inner_join(sent_words, by = "word") %>%
  ungroup() %>%
  distinct()
```

Sentiment of Tweets with a Policy Focused Message - Message Variable

```{r}
policy.sentiments = tweet.sentiments3 %>%
  filter(message=="policy")
```

```{r}
mean(policy.sentiments$value)
```

```{r}
policy.value=policy.sentiments$value
hist(policy.value)
```

Mean sentiment of words in tweets discussing policy is -0.08. Tweets focused on policy are largely a wash - politicians tweet negatively about policies they oppose, and positively about those they support.

Sentiment of Tweets with an Attack Message - Message Variable

```{r}
attack.sentiments = tweet.sentiments3 %>%
  filter(message=="attack")
```

```{r}
mean(attack.sentiments$value)
```

```{r}
attack.value=attack.sentiments$value
hist(attack.value)
```

Mean sentiment of words used in tweets with a message meant to attack is -0.53. This makes sense - when attacking another politician, party, or policy, using negative language is necessary. This is reflected in the histogram - these tweets have an extremely high frequency of quite negative words.

Sentiment of Tweets with a Support Message - Message Variable

```{r}
supp.sentiments = tweet.sentiments3 %>%
  filter(message=="support")
```

```{r}
mean(supp.sentiments$value)
```

```{r}
supp.value=supp.sentiments$value
hist(supp.value)
```

Tweets with a message meant to support have words with a mean sentiment value of 0.22. This makes sense - supportive messages need positive words. This is also backed up by the histogram - these tweets have high frequency of decently positive words.

Sentiment of Tweets with a message focused on Informing - Message Variable

```{r}
info.sentiments = tweet.sentiments3 %>%
  filter(message=="information")
```

```{r}
mean(info.sentiments$value)
```

```{r}
info.value=info.sentiments$value
hist(info.value)
```

Tweets meant to inform have words with a mean sentiment value of 0.07. This variable being a wash is intuitive. Politicians have to inform their followers of both positive and negative events, and it makes sense they would use language in line with that sentiment in both cases. This is reflected in the similar frequency of positive and negative words displayed in the histogram.

Sentiment of Tweets with a Personal Message - Message Variable

```{r}
personal.sentiments = tweet.sentiments3 %>%
  filter(message=="personal")
```

```{r}
mean(personal.sentiments$value)
```

```{r}
personal.value=personal.sentiments$value
hist(personal.value)
```

Words in tweets with a personal message have a mean sentiment value of 0.44. This is also intuitive. When politicians share personal messages or information, it is most often to build up their own brand. It makes sense they would use more positive language to do this, and that's backed up by the histogram which shows high intensity of positive words in these tweets.

Sentiment of Tweets focused on Voter Mobilization - Message Variable

```{r}
mobil.sentiments = tweet.sentiments3 %>%
  filter(message=="mobilization")
```

```{r}
mean(mobil.sentiments$value)
```

```{r}
mobil.value=mobil.sentiments$value
hist(mobil.value)
```

Words in tweets meant to mobilize voters have an average sentiment of 0.5. When politicians want to mobilize their followers, they share positive messages about things like the possibility of good change in the world. Few people are encouraged by messages of hate. This is reinforced by the histogram which shows mostly positive words in these tweets.

Sentiment of Tweets with a message focused on the politician's constituency - Message Variable

```{r}
cons.sentiments.msg = tweet.sentiments3 %>%
  filter(message=="constituency")
```

```{r}
mean(cons.sentiments.msg$value)
```

```{r}
cons.msg.value=cons.sentiments.msg$value
hist(cons.msg.value)
```

Mean sentiment of words in constituency-focused tweets is 1.16. This is the highest average sentiment value we've seen yet. This also makes sense. When politicians are sharing messages about their constituency, even in negative circumstances, they tend to use positive language. They want to describe their constituents in a positive light at almost all times, and any negative language used in these tweets is likely not describing the constituents themselves. This is visible in the histogram which shows an extremely skewed distribution heavily favoring positive words.

Whole Tweet Sentiment Analysis - Message Variable

```{r}
data4 = read_csv("political_social_media.csv") %>%
  select(-"_golden", -"_unit_state", -"_trusted_judgments", -"_last_judgment_at", -"audience:confidence", -"message:confidence", -"orig__golden", -"audience_gold", -"bias_gold", -bioid, -embed, -label, -"message_gold", -source, -"bias:confidence", -"_unit_id", -bias, -audience)

data.token4 = data4 %>%
  unnest_tokens(word, text, token = "words")

data.token_nostop4 = data.token4 %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("http","t.co","amp","day","rt","1","week","watch","morning","2","3","4","5","6","7","8","9","10","2013","2014","2015","2016","2017","2018","2019"))

tweet.sentiments4 = data.token_nostop4 %>%
  inner_join(sent_words, by = "word") %>%
  group_by(id) %>%
  mutate(sentiment = mean(value)) %>%
  ungroup() %>%
  select(-value, -word) %>%
  distinct()
```

```{r}
ggplot(tweet.sentiments4, aes(x=sentiment, fill=message)) +
  geom_density(alpha=.25) +
  theme_economist_white()
```

Here, I analyzed the average sentiment of a given tweet based on all the relevant words in it. The accompanying graph then shows the distribution of tweet sentiment across different message focuses. As is visible in the graph, tweets with a message focused on constituency are the most positive, followed by tweets with a personal message. Tweets with a message focused on attacking are by far the most negative.

Whole Tweet Sentiment Analysis - Bias Variable

```{r}
data5 = read_csv("political_social_media.csv") %>%
  select(-"_golden", -"_unit_state", -"_trusted_judgments", -"_last_judgment_at", -"audience:confidence", -message, -"message:confidence", -"orig__golden", -"audience_gold", -"bias_gold", -bioid, -embed, -label, -"message_gold", -source, -"bias:confidence", -"_unit_id", -audience)

data.token5 = data5 %>%
  unnest_tokens(word, text, token = "words")

data.token_nostop5 = data.token5 %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("http","t.co","amp","day","rt","1","week","watch","morning","2","3","4","5","6","7","8","9","10","2013","2014","2015","2016","2017","2018","2019"))

tweet.sentiments5 = data.token_nostop5 %>%
  inner_join(sent_words, by = "word") %>%
  group_by(id) %>%
  mutate(sentiment = mean(value)) %>%
  ungroup() %>%
  select(-value, -word) %>%
  distinct()
```

```{r}
ggplot(tweet.sentiments5, aes(x=sentiment, fill=bias)) +
  geom_density(alpha=.25) +
  theme_economist_white()
```

Here, I analyzed the sentiment of entire tweets based on the positivity/negativity of each word in them split by partisan or neutral bias. Partisan tweets are more negative, while neutral tweets are more biased. This backs up the trend of political polarization and the trend of moving away from bipartisanship discussed earlier.

Whole Tweet Sentiment Analysis - Audience Variable

```{r}
data6 = read_csv("political_social_media.csv") %>%
  select(-"_golden", -"_unit_state", -"_trusted_judgments", -"_last_judgment_at", -"audience:confidence", -message, -"message:confidence", -"orig__golden", -"audience_gold", -"bias_gold", -bioid, -embed, -label, -"message_gold", -source, -"bias:confidence", -"_unit_id", -bias)

data.token6 = data6 %>%
  unnest_tokens(word, text, token = "words")

data.token_nostop6 = data.token6 %>%
  anti_join(stop_words, by = "word") %>%
  filter(!word %in% c("http","t.co","amp","day","rt","1","week","watch","morning","2","3","4","5","6","7","8","9","10","2013","2014","2015","2016","2017","2018","2019"))

tweet.sentiments6 = data.token_nostop6 %>%
  inner_join(sent_words, by = "word") %>%
  group_by(id) %>%
  mutate(sentiment = mean(value)) %>%
  ungroup() %>%
  select(-value, -word) %>%
  distinct()
```

```{r}
ggplot(tweet.sentiments6, aes(x=sentiment, fill=audience)) +
  geom_density(alpha=.25) +
  theme_economist_white()
```

Here, I analyzed the sentiment of entire tweets split by their focus on a politician's local constituency or the entire nation. Tweets aimed at the entire nation are more negative while tweets aimed at a politician's local constituency are more positive.
